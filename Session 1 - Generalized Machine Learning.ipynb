{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generalized Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Machine Learning Problem\n",
    "\n",
    "Given a set of $n$ samples of data such that each sample is represented by more than a single number, e.g. multivariate data that has several attributes or features, create a model that is able to predict unknown properties of each sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Spatial interpretation_: given data points in a bounded, high dimensional space, define regions of decisions for any point in that space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learning by Example\n",
    "\n",
    "Given a bunch of examples (data) extract a meaningful pattern upon which to act.\n",
    "\n",
    "![Learning from examples](figures/learning_from_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Types of Algorithms\n",
    "\n",
    "Input _training_ data to fit a model which is then used to predict incoming inputs into ...\n",
    "\n",
    "![Categorized by output type](figures/cat_by_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Terminology\n",
    "\n",
    "<dl style=\"margin-top:20px\">\n",
    "    <dt>Instance</dt>\n",
    "        <dd>A single data point or example composed of multiple fields.<br/>Should be able to describe instances as a noun.</dd>\n",
    "    <dt>Feature</dt>\n",
    "        <dd>A numeric quantity describing an instance</dd>\n",
    "    <dt>Target</dt>\n",
    "        <dd>The property or field that we're trying to predict</dd>\n",
    "    <dt>Dimension</dt>\n",
    "        <dd>A semi-bounded region whose range describes all possible values of a feature</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression\n",
    "\n",
    "![regression](figures/regression.png)\n",
    "\n",
    "**Hypothesis:** Given continuous input data fit a function that is able to predict the continuous value of input given other data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: add code to generate above image to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price = 25.45 for:\n",
      "CRIM: 0.006\n",
      "ZN: 18.000\n",
      "INDUS: 2.310\n",
      "CHAS: 0.000\n",
      "NOX: 0.538\n",
      "RM: 6.575\n",
      "AGE: 65.200\n",
      "DIS: 4.090\n",
      "RAD: 1.000\n",
      "TAX: 296.000\n",
      "PTRATIO: 15.300\n",
      "B: 396.900\n",
      "LSTAT: 4.980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load Dataset \n",
    "boston = load_boston()\n",
    "\n",
    "# Fit a model to the data and target \n",
    "model = RandomForestRegressor()\n",
    "model.fit(boston.data, boston.target)\n",
    "\n",
    "# Make predictions on the data\n",
    "predicted = model.predict(boston.data)\n",
    "\n",
    "print(\"Predicted Price = {:0.2f} for:\".format(predicted[0]))\n",
    "print(\"\\n\".join([\"{}: {:0.3f}\".format(k,v) for k, v in zip(boston.feature_names, boston.data[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest regression model on Boston housing dataset\n",
      "Mean squared error: 2.2800126482213443\n",
      "R2 score: 0.9729918901255107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "expected = boston.target\n",
    "print(\"Random forest regression model on Boston housing dataset\")\n",
    "print(\"Mean squared error: {}\".format(mse(expected, predicted)))\n",
    "print(\"R2 score: {}\".format(r2_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "![classification](figures/classification.png)\n",
    "\n",
    "**Hypothesis:** Given labeled input data (with two or more labels), fit a function that can determine for any input, what the label is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: add code to generate above image to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class = \"setosa\" for:\n",
      "sepal length (cm): 5.100\n",
      "sepal width (cm): 3.500\n",
      "petal length (cm): 1.400\n",
      "petal width (cm): 0.200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "model = SVC()\n",
    "model.fit(iris.data, iris.target)\n",
    "\n",
    "predicted = model.predict(iris.data)\n",
    "\n",
    "print(\"Predicted Class = \\\"{}\\\" for:\".format(iris.target_names[predicted[0]]))\n",
    "print(\"\\n\".join([\"{}: {:0.3f}\".format(k,v) for k, v in zip(iris.feature_names, iris.data[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier on Iris dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        50\n",
      " versicolor       1.00      0.96      0.98        50\n",
      "  virginica       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "expected = iris.target\n",
    "\n",
    "print(\"SVM Classifier on Iris dataset\")\n",
    "print(classification_report(expected, predicted, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "![clustering](figures/clustering.png)\n",
    "\n",
    "**Hypothesis:** Given data, determine a pattern of associated data points or clusters via their similarity or distance from one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: add code to generate above image to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cols = [\"Fresh\",\"Milk\",\"Grocery\",\"Frozen\",\"Detergents_Paper\",\"Delicassen\"]\n",
    "data = pd.read_csv(\"data/customers.txt\", usecols=cols)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(data)\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(reduced)\n",
    "\n",
    "centroids = model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score of KMeans (k=3) on the Customer dataset\n",
      "0.5229120824043509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "print(\"Silhouette score of KMeans (k=3) on the Customer dataset\")\n",
    "print(silhouette_score(reduced, model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: move to utils and import \n",
    "def draw_clusters(model=model, reduced=reduced):\n",
    "    _, ax = plt.subplots(figsize=(9,6))\n",
    "    centroids = model.cluster_centers_\n",
    "    \n",
    "    for i in range(centroids.shape[0]):\n",
    "        datapoints = reduced[np.where(model.labels_==i)]\n",
    "        \n",
    "        ax.plot(datapoints[:,0],datapoints[:,1], '.')\n",
    "    \n",
    "    centers = ax.plot(centroids[:,0],centroids[:,1],'x', markersize=20, mew=5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlabel(\"principle component 0\")\n",
    "    ax.set_ylabel(\"principle component 1\")    \n",
    "    \n",
    "    return ax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: add code above to utils, and potentially create a new Yellowbrick visualizer from it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1228b66a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalized Machine Learning\n",
    "\n",
    "The spatial interpretation of machine learning has led to a generalized framework that encompasses a large range of statistical techniques and optimization procedures. The generalization is specified by the primary components of a model:\n",
    "\n",
    "- Features and training data \n",
    "- Algorithm and optimization \n",
    "- Parameters and hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Features\n",
    "\n",
    "Features are the numeric properties that represent _instances_ - the samples of data that we learn on. All machine learning requires a data set of _sufficient size_ in order to train models; the size of the dataset required often depends on the number of features required for predictability. \n",
    "\n",
    "![feature space](figures/feature_space.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Space\n",
    "\n",
    "Feature space refers to the n-dimensions where your variables live (not including a target variable or class). The term is used often in ML literature because in ML all variables are features (usually) and feature extraction is the art of creating a space with decision boundaries. \n",
    "\n",
    "**Target**\n",
    "- Y ≡ Thickness of car tires after some testing period\n",
    "\n",
    "**Variables**\n",
    "- X1 ≡ distance travelled in test\n",
    "- X2 ≡ time duration of test\n",
    "- X3 ≡ amount of chemical C in tires\n",
    "\n",
    "The feature space is R3, or more accurately, the positive quadrant in R3 as all the X variables can only be positive quantities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mappings and Transformations\n",
    "\n",
    "Domain knowledge about tires might suggest that the speed the vehicle was moving at is important, hence we generate another variable, X4 (this is the feature extraction part):\n",
    "\n",
    "X4 = X1 / X2 ≡ the speed of the vehicle during testing.\n",
    "\n",
    "This extends our old feature space into a new one, the positive part of R4.\n",
    "\n",
    "A mapping is a function, $\\phi$, from R3 to R4:\n",
    "\n",
    "\n",
    "$$\\phi(x1,x2,x3) = (x1,x2,x3,x1x2)$$\n",
    "\n",
    "![mapping](figures/mapping.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Extraction \n",
    "\n",
    "Real-world data is often not represented numerically out of the box (e.g. text, images), therefore some transformation must be applied in order to do machine learning. \n",
    "\n",
    "![Hand Written Digits](figures/hand_written_digits.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data      # X.shape == (n_samples, n_features)\n",
    "y = digits.target    # y.shape == (n_samples,)\n",
    "\n",
    "X[0]                 # Feature representation of first instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "“feature engineering is another topic which doesn’t seem to merit any review papers or books, or even chapters in books, but it is absolutely vital to ML success... Much of the success of machine learning is actually success in engineering features that a learner can understand.” \n",
    "\n",
    "Scott Locklin, in “Neglected machine learning ideas”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n",
    "\n",
    "Jason Brownlee, in “Discover Feature Engineering”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models\n",
    "\n",
    "“Model” is an overloaded term.\n",
    "\n",
    "- **Model family** describes, at the broadest possible level, the connection between the variables of interest. \n",
    "- **Model form** specifies exactly how the variables of interest are connected within the framework of the model family. \n",
    "- **A fitted model** is a concrete instance of the model form where all parameters have been estimated from data, and the model can be used to generate predictions.\n",
    "\n",
    "\n",
    "&mdash; Hadley Wickham (http://had.co.nz/stat645/model-vis.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameters and Hyperparameters\n",
    "\n",
    "- Models are essentially black boxes, when fitted they learn an internal representation of the decision space which we will generically call _parameters_ here. The parameters (e.g. coefficients of a linear regression) should only be learned from data and not modified by users. \n",
    "- Hyperparameters are the attributes supplied by the user that govern the behavior of the model during both the fit and the prediction process. They are called hyperparameters because they are \"below the decision space\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning API\n",
    "\n",
    "Scikit-Learn's primary contribution was an API for machine learning, which has since been adpoted by many other libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Choosing the Right Estimator](figures/choosing_estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Object-oriented interface centered around the concept of an Estimator: \n",
    "\n",
    "> “An estimator is any object that learns from data; it may be a classification, regression or clustering algorithm or a transformer that extracts/filters useful features from raw data.”\n",
    "\n",
    "&mdash; Scikit-Learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Estimators\n",
    "\n",
    " - `fit(X,y)` sets the state of the estimator.\n",
    " - `X` is usually a 2D `numpy` array of shape `(num_samples, num_features)`.\n",
    " - `y` is a 1D array with shape `(n_samples,)`\n",
    " - When can `y` be `None`?\n",
    " - `Fit` returns `self`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Estimator(object):\n",
    "    \n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of all hyperparams \n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Sets hyperparams on the instance \n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fit the estimator from data\n",
    "        \"\"\"\n",
    "        # Modify state of self \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predictors\n",
    "\n",
    " - `predict(X)` returns the class or value\n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - Returns a 1D vector with shape `(n_rows,)`\n",
    " - `predict_proba()` or `decision_function()` returns a 2D array of shape `(n_rows, n_classes)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Predictor(Estimator):\n",
    "    \n",
    "    def predict(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict values for each row in X \n",
    "        \"\"\"\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "from sklearn import svm\n",
    "\n",
    "estimator = svm.SVC(gamma=0.001)\n",
    "estimator.fit(X, y)\n",
    "estimator.predict(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models \n",
    "\n",
    " - `score(X, y=None)` returns a descriptive metric between 0 and 1 where 0 is bad and 1 is good. \n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - `y` is optionally a 1D vector with \"correct labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Model(Predictor):\n",
    "    \n",
    "    def score(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Return a score between 0 and 1\n",
    "        \"\"\"\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformers\n",
    "\n",
    " - `transform(X)` transforms input data to prepare it for ML.\n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - `X_prime` is a 2D `numpy` array with shape `(m_rows, m_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(Estimator):\n",
    "    \n",
    "    def transform(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Modifies X and returns a new X' \n",
    "        \"\"\"\n",
    "        return X_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Scikit-Learn provides a utility package, preprocessing to transform raw feature vectors into representations that assist downstream processing, including:\n",
    "\n",
    "- **Standardization**: transform data to mean = zero and unit variance. \n",
    "- **Scaling**: transform feature to lie between range, usually `[0,1]`\n",
    "- **Normalization**: scaling features to a unit norm\n",
    "- **Binarization**: thresholding features to get binary values\n",
    "- **Label Encoding**: transforming labels to numeric values\n",
    "- **Imputation**: infer missing values from known parts of the data\n",
    "- **Data Reduction**: use unsupervised methods to reduce dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipelines\n",
    "\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated and operationalized together.\n",
    "\n",
    "Sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement `fit()` and `transform()` methods. The final estimator only needs to implement `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Pipeline(Transformer):\n",
    "\n",
    "    @property\n",
    "    def named_steps(self):\n",
    "        \"\"\"\n",
    "        Sequence of estimators\n",
    "        \"\"\"\n",
    "        return self.steps\n",
    "\n",
    "    @property\n",
    "    def _final_estimator(self):\n",
    "        \"\"\"\n",
    "        Terminating estimator\n",
    "        \"\"\"\n",
    "        return self.steps[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "Generalized machine learning and the Scikit-Learn API gives us the ability to fit a large number of models on the same data with ease; so how do you select a model for decision making?\n",
    "\n",
    "Goals for models:\n",
    "\n",
    "- Separability \n",
    "- Generalizability \n",
    "- Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Separability](figures/separability.png)\n",
    "\n",
    "- Models are able to easily distinguish patterns in feature space\n",
    "- Patterns can be “separated” with a hyperplane or region\n",
    "- Decreased covariance between features that describe instances\n",
    "- Loosely: “noiseless”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Generalizability](figures/generalizability.png)\n",
    "\n",
    "- Models are able to make predictions on new inputs. \n",
    "- Complete view of the decision region, no narrow windows of decision making or limited information gain (sparsity). \n",
    "- Loosely: “model is sufficient”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Selection Triple\n",
    "\n",
    "![Model Selection Triple](figures/model_selection_triple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Search Problem\n",
    "\n",
    "- **Compose** as many model triples as you can think of \n",
    "- **Fit and Evaluate** models in parallel with cluster computing \n",
    "- **Find** the best model for your application via scoring metrics \n",
    "\n",
    "&hellip;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visual Steering\n",
    "\n",
    "![Visual Steering](figures/visual_steering.png)\n",
    "\n",
    "- Interventions or guidance by human pattern recognition. \n",
    "- Humans engage the modeling process through visualization. \n",
    "- Overview first, zoom and filter, details on demand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complexity\n",
    "\n",
    "- The \"dial\" that data scientists can turn to adjust the performance of a model is its _complexity_. \n",
    "- There is a trade-off in bias (error due to simple models) and variance (error due to complex models)\n",
    "- Throughout our discussions of models, always ask: \"where are the sources of complexity?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias and Variance\n",
    "\n",
    "![Bias Variance](figures/bias_variance.png)\n",
    "\n",
    "- **Bias**: the difference between expected (average) prediction of the model and the correct value. \n",
    "- **Variance**: how the predictions for a given point vary between different realizations for the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias/Variance Trade-Off\n",
    "\n",
    "![Bias Variance Tradeoff](figures/bias_variance_tradeoff.png)\n",
    "\n",
    "Related to model complexity:\n",
    "The more parameters added to the model (the more complex), Bias is reduced, and variance increased.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Underfitting\n",
    "\n",
    "![Underfitting](figures/underfitting.png)\n",
    "\n",
    "Not enough information to accurately model real life. Can be due to high bias, or just a too simplistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "![Overfitting](figures/overfitting.png)\n",
    "\n",
    "Create a model with too many parameters or is too complex. “Memorization of the data” - and the model can’t generalize very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-Validation\n",
    "\n",
    "![Cross-Validation](figures/cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sources of Complexity\n",
    "\n",
    "- Adding and Removing Features \n",
    "- Hyperparameters \n",
    "- Amount of training data \n",
    "- Different algorithmic methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretability\n",
    "\n",
    "Given two models with similar scoring metrics, select the model that is more explainable. \n",
    "\n",
    "Goal: find the _least complex_ model that is adequately predictable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deployment\n",
    "\n",
    "While discussing machine learning, it's easy to forget that the purpose of a model is to be used in decision making - the model itself is not the end goal! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saving Models \n",
    "\n",
    "Models can be saved to disk or a database for use in applications or for archival purposes:\n",
    "\n",
    "- **Pickle**: Python-specific model saving, works for any model\n",
    "- **PMML**: Generic, cross-language model specification, but only for a handful of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification/Regression Workflow\n",
    "\n",
    "![Classification/Regression Workflow](figures/classification_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering Workflow\n",
    "\n",
    "![Clustering Workflow](figures/clustering_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Product Pipeline\n",
    "\n",
    "![Data Product Pipeline](figures/data_product_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tour of Model Families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models: Instance Methods\n",
    "\n",
    "Compare instances in data set with a similarity measure to find best matches. \n",
    "\n",
    "Suffers from curse of dimensionality. \n",
    "\n",
    "Focus on feature representation and similarity metrics between instances\n",
    "\n",
    " - k-Nearest Neighbors (kNN)\n",
    " - Self-Organizing Maps (SOM)\n",
    " - Learning Vector Quantization (LVQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regression Models\n",
    "\n",
    "Model relationship of independent variables, X to dependent variable Y by iteratively optimizing error made in predictions.\n",
    "\n",
    " - Ordinary Least Squares\n",
    " - Logistic Regression\n",
    " - Stepwise Regression\n",
    " - Multivariate Adaptive Regression Splines (MARS)\n",
    " - Locally Estimated Scatterplot Smoothing (LOESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regularization Methods\n",
    "\n",
    "Extend another method (usually regression), penalizing complexity (minimize overfit)\n",
    "\n",
    "simple, popular, powerful \n",
    "\n",
    "better at generalization\n",
    "\n",
    " - Ridge Regression (L2)\n",
    " - LASSO (Least Absolute Shrinkage & Selection Operator) (L1)\n",
    " - Elastic Net (L1 + L2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Trees\n",
    "\n",
    "Model of decisions based on data attributes. Predictions are made by following forks in a tree structure until a decision is made. Used for classification & regression.\n",
    "\n",
    " - Classification and Regression Tree (CART)\n",
    " - Decision Stump\n",
    " - Random Forest\n",
    " - Multivariate Adaptive Regression Splines (MARS)\n",
    " - Gradient Boosting Machines (GBM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Models\n",
    "\n",
    "Explicitly apply Bayes’ Theorem for classification and regression tasks. Usually by fitting a probability function constructed via the chain rule and a naive simplification of Bayes.\n",
    "\n",
    " - Naive Bayes\n",
    " - Averaged One-Dependence Estimators (AODE)\n",
    " - Bayesian Belief Network (BBN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Kernel Methods\n",
    "\n",
    "Map input data into higher dimensional vector space where the problem is easier to model. Named after the “kernel trick” which computes the inner product of images of pairs of data.\n",
    "\n",
    " - Support Vector Machines (SVM)\n",
    " - Radial Basis Function (RBF)\n",
    " - Linear Discriminant Analysis (LDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering Methods\n",
    "\n",
    "Organize data into groups whose members share maximum similarity (defined usually by a distance metric). Two main approaches: centroids and hierarchical clustering.\n",
    "\n",
    " - k-Means\n",
    " - Affinity Propagation\n",
    " - OPTICS (Ordering Points to Identify Cluster Structure)\n",
    " - Agglomerative Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "Inspired by biological neural networks, ANNs are nonlinear function approximators that estimate functions with a large number of inputs.\n",
    "\n",
    "System of interconnected neurons that activate \n",
    "\n",
    "Deep learning extends simple networks recursively\n",
    "\n",
    " - Perceptron\n",
    " - Back-Propagation\n",
    " - Hopfield Network\n",
    " - Restricted Boltzmann Machine (RBM)\n",
    " - Deep Neural Networks (DBN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ensemble Models\n",
    "\n",
    "Models composed of multiple weak models that are trained independently and whose outputs are combined to make an overall prediction.\n",
    "\n",
    " - Boosting\n",
    " - Bootstrapped Aggregation (Bagging)\n",
    " - AdaBoost\n",
    " - Stacked Generalization (blending)\n",
    " - Gradient Boosting Machines (GBM)\n",
    " - Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Other Models\n",
    "\n",
    "The list so far is no where near comprehensive, other algorithm and model classes include:\n",
    "\n",
    " - Conditional Random Fields (CRF)\n",
    " - Markovian Models (HMMs)\n",
    " - Dimensionality Reduction (PCA, PLS)\n",
    " - Rule Learning (Apriori, Brill)\n",
    " - More ...\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
