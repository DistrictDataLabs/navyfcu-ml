{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generalized Machine Learning \n",
    "\n",
    "- A spatial description of the ML problem \n",
    "- The bias/variance trade-off \n",
    "- Model selection and search \n",
    "- Generalized machine learning \n",
    "- Deploying machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "“A field of study that gives computers the ability to learn without being explicitly programmed.” \n",
    "\n",
    "\n",
    "Arthur Samuel (1959)\n",
    "\n",
    "![Arthur Samuel](figures/arthur_samuel.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"As babies, we watch our environments and start to understand the structure of objects we encounter, but until a parent tells us what it is, we can’t put a name to it...\" \n",
    "\n",
    "![Andrew Ng](figures/andrew_ng.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"...With Deep Learning, you just give the system a lot of data so it can discover by itself what some of the concepts in the world are. Last year, one of his algorithms taught itself to recognize cats after scanning millions of images on the internet. The algorithm didn’t know the word 'cat' — scientists had to supply that — but over time, it learned to identify the furry creatures we know as cats, all on its own.\"\n",
    "\n",
    "\n",
    "Meta-cat:\n",
    "\n",
    "![Cat Detection](figures/cat_detection.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"Throughout the eighties and nineties, it was striking how many times people working within the 'ML community' realized that their ideas had had a lengthy pre-history in statistics. Decision trees, nearest neighbor, logistic regression, kernels, PCA, canonical correlation, graphical models, K- means and discriminant analysis come to mind, and also many general methodological principles...\"\n",
    "\n",
    "![Michael Jordan](figures/michael_jordan.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"...In general, 'statistics' refers in part to an analysis style - a statistician is happy to analyze the performance of any system, ... if it takes in data that can be considered random and outputs decisions that can be considered uncertain...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"...I don't think that the 'ML community' has developed many new inferential principles - or many new optimization principles - but I do think that the community has been exceedingly creative at taking existing ideas across many fields, and mixing and matching them to solve problems in emerging problem domains, and I think that the community has excelled at making creative use of new computing architectures.\" \n",
    "\n",
    "\n",
    "Michael Jordan (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Venn Diagram](figures/venn_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Machine Learning Context to Data Mining and Statistics](figures/ml_context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data Science *is* Machine Learning \n",
    "\n",
    "The art of machine learning is to fit existing data to some model, creating a parameterized representation of the real world that is able to make decisions or predictions on new data based on previously discovered patterns. Models that are created from data are used in data products as the engines that create actionable results and generate even more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, a learning problem considers a set of n samples of data and then tries to predict properties of unknown data. \n",
    "\n",
    "If each sample is more than a single number, for instance, a multidimensional entry (aka multivariate data), is it said to have several attributes or features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learning from Examples\n",
    "\n",
    "Given a bunch of examples (data) extract a meaningful pattern upon which to act.\n",
    "\n",
    "![Learning from examples](figures/learning_from_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Categorized by Output Type\n",
    "\n",
    "Input training data to fit a model which is then used to predict incoming inputs into ...\n",
    "\n",
    "![Categorized by output type](figures/cat_by_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Terminology\n",
    "\n",
    "“Model” is an overloaded term.\n",
    "\n",
    "• Model family describes, at the broadest possible level, the connection between the variables of interest. \n",
    "\n",
    "• Model form specifies exactly how the variables of interest are connected within the framework of the model family. \n",
    "\n",
    "• A fitted model is a concrete instance of the model form where all parameters have been estimated from data, and the model can be used to generate predictions.\n",
    "\n",
    "\n",
    "Hadley Wickham (2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "![regression](figures/regression.png)\n",
    "\n",
    "Given continuous input data fit a function that is able to predict the continuous value of input given other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(boston.data, boston.target)\n",
    "\n",
    "expected = boston.target\n",
    "predicted = model.predict(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest regression model on Boston housing dataset\n",
      "Mean squared error: 1.8013905138339914\n",
      "R2 score: 0.9786614548114699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "print(\"Random forest regression model on Boston housing dataset\")\n",
    "print(\"Mean squared error: {}\".format(mse(expected, predicted)))\n",
    "print(\"R2 score: {}\".format(r2_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "![classification](figures/classification.png)\n",
    "\n",
    "Given labeled input data (with two or more labels), fit a function that can determine for any input, what the label is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "model = SVC()\n",
    "model.fit(iris.data, iris.target)\n",
    "\n",
    "expected = iris.target\n",
    "predicted = model.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier on Iris dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        50\n",
      " versicolor       1.00      0.96      0.98        50\n",
      "  virginica       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "classes = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "print(\"SVM Classifier on Iris dataset\")\n",
    "print(classification_report(expected, predicted, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "![clustering](figures/clustering.png)\n",
    "\n",
    "Given data, determine a pattern of associated data points or clusters via their similarity or distance from one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "\n",
    "\n",
    "UCI_CUSTOMER_DATA_URL = \"https://bit.ly/2COHM14\"\n",
    "response = requests.get(UCI_CUSTOMER_DATA_URL)\n",
    "outpath  = os.path.abspath(\"data/customers.txt\")\n",
    "with open(outpath, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "cols = [\"Fresh\",\"Milk\",\"Grocery\",\"Frozen\",\"Detergents_Paper\",\"Delicassen\"]\n",
    "data = pd.read_csv(\"data/customers.txt\", usecols=cols)\n",
    "customers = data.values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(customers)\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(reduced)\n",
    "\n",
    "labels = model.labels_\n",
    "centroids = model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score of KMeans (k=3) on the Customer dataset\n",
      "0.5229120824043509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "print(\"Silhouette score of KMeans (k=3) on the Customer dataset\")\n",
    "print(silhouette_score(reduced, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(3):\n",
    "    datapoints = reduced[np.where(labels==i)]\n",
    "    plt.plot(datapoints[:,0],datapoints[:,1],'.')\n",
    "    centers = plt.plot(centroids[:,0],centroids[:,1],'x')\n",
    "    plt.setp(centers,markersize=20.0)\n",
    "    plt.setp(centers,markeredgewidth=5.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalized Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models: Instance Methods\n",
    "\n",
    "Compare instances in data set with a similarity measure to find best matches. \n",
    "\n",
    "Suffers from curse of dimensionality. \n",
    "\n",
    "Focus on feature representation and similarity metrics between instances\n",
    "\n",
    " - k-Nearest Neighbors (kNN)\n",
    " - Self-Organizing Maps (SOM)\n",
    " - Learning Vector Quantization (LVQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regression Models\n",
    "\n",
    "Model relationship of independent variables, X to dependent variable Y by iteratively optimizing error made in predictions.\n",
    "\n",
    " - Ordinary Least Squares\n",
    " - Logistic Regression\n",
    " - Stepwise Regression\n",
    " - Multivariate Adaptive Regression Splines (MARS)\n",
    " - Locally Estimated Scatterplot Smoothing (LOESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularization Methods\n",
    "\n",
    "Extend another method (usually regression), penalizing complexity (minimize overfit)\n",
    "\n",
    "simple, popular, powerful \n",
    "\n",
    "better at generalization\n",
    "\n",
    " - Ridge Regression (L2)\n",
    " - LASSO (Least Absolute Shrinkage & Selection Operator) (L1)\n",
    " - Elastic Net (L1 + L2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Decision Trees\n",
    "\n",
    "Model of decisions based on data attributes. Predictions are made by following forks in a tree structure until a decision is made. Used for classification & regression.\n",
    "\n",
    " - Classification and Regression Tree (CART)\n",
    " - Decision Stump\n",
    " - Random Forest\n",
    " - Multivariate Adaptive Regression Splines (MARS)\n",
    " - Gradient Boosting Machines (GBM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bayesian Models\n",
    "\n",
    "Explicitly apply Bayes’ Theorem for classification and regression tasks. Usually by fitting a probability function constructed via the chain rule and a naive simplification of Bayes.\n",
    "\n",
    " - Naive Bayes\n",
    " - Averaged One-Dependence Estimators (AODE)\n",
    " - Bayesian Belief Network (BBN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Kernel Methods\n",
    "\n",
    "Map input data into higher dimensional vector space where the problem is easier to model. Named after the “kernel trick” which computes the inner product of images of pairs of data.\n",
    "\n",
    " - Support Vector Machines (SVM)\n",
    " - Radial Basis Function (RBF)\n",
    " - Linear Discriminant Analysis (LDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Clustering Methods\n",
    "\n",
    "Organize data into groups whose members share maximum similarity (defined usually by a distance metric). Two main approaches: centroids and hierarchical clustering.\n",
    "\n",
    " - k-Means\n",
    " - Affinity Propagation\n",
    " - OPTICS (Ordering Points to Identify Cluster Structure)\n",
    " - Agglomerative Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Artificial Neural Networks\n",
    "\n",
    "Inspired by biological neural networks, ANNs are nonlinear function approximators that estimate functions with a large number of inputs.\n",
    "\n",
    "System of interconnected neurons that activate \n",
    "\n",
    "Deep learning extends simple networks recursively\n",
    "\n",
    " - Perceptron\n",
    " - Back-Propagation\n",
    " - Hopfield Network\n",
    " - Restricted Boltzmann Machine (RBM)\n",
    " - Deep Neural Networks (DBN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ensemble Models\n",
    "\n",
    "Models composed of multiple weak models that are trained independently and whose outputs are combined to make an overall prediction.\n",
    "\n",
    " - Boosting\n",
    " - Bootstrapped Aggregation (Bagging)\n",
    " - AdaBoost\n",
    " - Stacked Generalization (blending)\n",
    " - Gradient Boosting Machines (GBM)\n",
    " - Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Other Models\n",
    "\n",
    "The list before was not comprehensive, other algorithm and model classes include:\n",
    "\n",
    " - Conditional Random Fields (CRF)\n",
    " - Markovian Models (HMMs)\n",
    " - Dimensionality Reduction (PCA, PLS)\n",
    " - Rule Learning (Apriori, Brill)\n",
    " - More ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features\n",
    "\n",
    "In order to do machine learning you need a data set containing instances (examples) that are composed of features from which you compose dimensions. \n",
    "\n",
    "**Instance**: a single data point or example composed of fields\n",
    "\n",
    "**Feature**: a numeric quantity describing an instance \n",
    "\n",
    "**Dimension**: one or more attributes that describe a property\n",
    "\n",
    "![feature space](figures/feature_space.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data      # X.shape == (n_samples, n_features)\n",
    "y = digits.target    # y.shape == (n_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Feature space refers to the n-dimensions where your variables live (not including a target variable or class). The term is used often in ML literature because in ML all variables are features (usually) and feature extraction is the art of creating a space with decision boundaries. \n",
    "\n",
    "**Target**\n",
    "Y ≡ Thickness of car tires after some testing period\n",
    "\n",
    "**Variables**\n",
    "X1 ≡ distance travelled in test\n",
    "X2 ≡ time duration of test\n",
    "X3 ≡ amount of chemical C in tires\n",
    "\n",
    "The feature space is R3, or more accurately, the positive quadrant in R3 as all the X variables can only be positive quantities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameters and Hyperparameters\n",
    "\n",
    "Domain knowledge about tires might suggest that the speed the vehicle was moving at is important, hence we generate another variable, X4 (this is the feature extraction part):\n",
    "\n",
    "X4 = X1 / X2 ≡ the speed of the vehicle during testing.\n",
    "\n",
    "This extends our old feature space into a new one, the positive part of R4.\n",
    "\n",
    "A mapping is a function, ϕ, from R3 to R4:\n",
    "\n",
    "ϕ(x1,x2,x3) = (x1,x2,x3,x1x2)\n",
    "\n",
    "![mapping](figures/mapping.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "“feature engineering is another topic which doesn’t seem to merit any review papers or books, or even chapters in books, but it is absolutely vital to ML success... Much of the success of machine learning is actually success in engineering features that a learner can understand.” \n",
    "\n",
    "Scott Locklin, in “Neglected machine learning ideas”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n",
    "\n",
    "Jason Brownlee, in “Discover Feature Engineering”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Choosing the Right Estimator](figures/choosing_estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Object-oriented interface centered around the concept of an Estimator: \n",
    "\n",
    "“An estimator is any object that learns from data; it may be a classification, regression or clustering algorithm or a transformer that extracts/filters useful features from raw data.”\n",
    "\n",
    "Scikit-Learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Estimators\n",
    "\n",
    " - `fit(X,y)` sets the state of the estimator.\n",
    " - `X` is usually a 2D `numpy` array of shape `(num_samples, num_features)`.\n",
    " - `y` is a 1D array with shape `(n_samples,)`\n",
    " - When can `y` be `None`?\n",
    " - `Fit` returns `self`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Estimator(object):\n",
    "    \n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of all hyperparams \n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Sets hyperparams on the instance \n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fit the estimator from data\n",
    "        \"\"\"\n",
    "        # Modify state of self \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predictors\n",
    "\n",
    " - `predict(X)` returns the class or value\n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - Returns a 1D vector with shape `(n_rows,)`\n",
    " - `predict_proba()` returns a 2D array of shape `(n_rows, n_classes)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Predictor(Estimator):\n",
    "    \n",
    "    def predict(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict values for each row in X \n",
    "        \"\"\"\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "from sklearn import svm\n",
    "\n",
    "estimator = svm.SVC(gamma=0.001)\n",
    "estimator.fit(X, y)\n",
    "estimator.predict(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Models \n",
    "\n",
    " - `score(X, y=None)` returns a descriptive metric between 0 and 1 where 0 is bad and 1 is good. \n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - `y` is optionally a 1D vector with \"correct labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Model(Predictor):\n",
    "    \n",
    "    def score(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Return a score between 0 and 1\n",
    "        \"\"\"\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformers\n",
    "\n",
    " - `transform(X)` transforms input data to prepare it for ML.\n",
    " - `X` is a 2D `numpy` array with shape `(n_rows, n_features)`\n",
    " - `X_prime` is a 2D `numpy` array with shape `(m_rows, m_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(Estimator):\n",
    "    \n",
    "    def transform(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Modifies X and returns a new X' \n",
    "        \"\"\"\n",
    "        return X_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Scikit-Learn provides a utility package, preprocessing to transform raw feature vectors into representations that assist downstream processing, including:\n",
    "\n",
    "**Standardization**: transform data to mean = zero and unit variance. \n",
    "**Scaling**: transform feature to lie between range, usually `[0,1]`\n",
    "**Normalization**: scaling features to a unit norm\n",
    "**Binarization**: thresholding features to get binary values\n",
    "**Label Encoding**: transforming labels to numeric values\n",
    "**Imputation**: infer missing values from known parts of the data\n",
    "**Data Reduction**: use unsupervised methods to reduce dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipelines\n",
    "\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated and operationalized together.\n",
    "\n",
    "Sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement `fit()` and `transform()` methods. The final estimator only needs to implement `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Pipeline(Transformer):\n",
    "\n",
    "    @property\n",
    "    def named_steps(self):\n",
    "        \"\"\"\n",
    "        Sequence of estimators\n",
    "        \"\"\"\n",
    "        return self.steps\n",
    "\n",
    "    @property\n",
    "    def _final_estimator(self):\n",
    "        \"\"\"\n",
    "        Terminating estimator\n",
    "        \"\"\"\n",
    "        return self.steps[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ok, I’ve fitted a model. How do I know if it’s any good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Selection Triple\n",
    "\n",
    "![Model Selection Triple](figures/model_selection_triple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Search Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visual Steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sources of Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification/Regression Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Product Pipeline"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
